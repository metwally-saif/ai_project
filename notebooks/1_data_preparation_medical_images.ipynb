{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = \"../data/medical_images/\"\n",
    "raw_images_dir = os.path.join(base_dir, \"raw/all_images/\")\n",
    "labels_csv = os.path.join(base_dir, \"raw/image_labels.csv\")\n",
    "\n",
    "# Define output directories\n",
    "train_dir = os.path.join(base_dir, \"train/\")\n",
    "val_dir = os.path.join(base_dir, \"val/\")\n",
    "test_dir = os.path.join(base_dir, \"test/\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "      filename  label\n",
      "0  image_0.jpg      0\n",
      "1  image_1.jpg      0\n",
      "2  image_2.jpg      0\n",
      "3  image_3.jpg      0\n",
      "4  image_4.jpg      0\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5856 entries, 0 to 5855\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  5856 non-null   object\n",
      " 1   label     5856 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 91.6+ KB\n",
      "None\n",
      "\n",
      "Number of Images: 5856\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(labels_csv)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Dataset information\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nNumber of Images: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "label\n",
      "1    4273\n",
      "0    1583\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split Sizes:\n",
      "Training Set: 4215 samples\n",
      "Validation Set: 469 samples\n",
      "Testing Set: 1172 samples\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df['label'], random_state=42)\n",
    "\n",
    "# Print the sizes of each split\n",
    "print(\"\\nSplit Sizes:\")\n",
    "print(f\"Training Set: {train_df.shape[0]} samples\")\n",
    "print(f\"Validation Set: {val_df.shape[0]} samples\")\n",
    "print(f\"Testing Set: {test_df.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def organize_images(dataframe, source_dir, target_dir):\n",
    "    \"\"\"\n",
    "    Copies images into class-labeled folders for a given dataframe.\n",
    "    \"\"\"\n",
    "    for _, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc=f\"Organizing {target_dir}\"):\n",
    "        label = row['label']\n",
    "        filename = row['filename']\n",
    "        src_path = os.path.join(source_dir, filename)\n",
    "        label_dir = os.path.join(target_dir, str(label))\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(label_dir, filename)\n",
    "        shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organizing ../data/medical_images/train/: 100%|██████████| 4215/4215 [01:05<00:00, 64.10it/s]\n",
      "Organizing ../data/medical_images/val/: 100%|██████████| 469/469 [00:06<00:00, 67.37it/s]\n",
      "Organizing ../data/medical_images/test/: 100%|██████████| 1172/1172 [00:15<00:00, 73.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Organize images into train, val, and test directories\n",
    "organize_images(train_df, raw_images_dir, train_dir)\n",
    "organize_images(val_df, raw_images_dir, val_dir)\n",
    "organize_images(test_df, raw_images_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Distribution:\n",
      "{'0': 1018, '1': 3076}\n",
      "\n",
      "Validation Set Distribution:\n",
      "{'0': 127, '1': 342}\n",
      "\n",
      "Testing Set Distribution:\n",
      "{'0': 305, '1': 855}\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_dir(directory):\n",
    "    \"\"\"\n",
    "    Counts the number of images in each subdirectory (class) under the given directory.\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    for label_dir in os.listdir(directory):\n",
    "        label_path = os.path.join(directory, label_dir)\n",
    "        if os.path.isdir(label_path):\n",
    "            counts[label_dir] = len(os.listdir(label_path))\n",
    "    return counts\n",
    "\n",
    "print(\"\\nTraining Set Distribution:\")\n",
    "print(count_images_in_dir(train_dir))\n",
    "\n",
    "print(\"\\nValidation Set Distribution:\")\n",
    "print(count_images_in_dir(val_dir))\n",
    "\n",
    "print(\"\\nTesting Set Distribution:\")\n",
    "print(count_images_in_dir(test_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "- Loaded and explored the image labels dataset.\n",
    "- Split the data into training, validation, and testing sets (80/10/10 split).\n",
    "- Organized the images into labeled subdirectories under `train/`, `val/`, and `test/`.\n",
    "- Saved the splits as CSV files for future reference.\n",
    "\n",
    "**Next Steps:**\n",
    "- Move on to model creation and training in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
